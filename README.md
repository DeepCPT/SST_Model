# Sequential Search Transformer (SST) - Monte Carlo Simulations

This repository contains the code implementation for the Monte Carlo simulations conducted to evaluate parameter recovery capabilities of the **Sequential Search Transformer (SST)**, as described in our recent study.

## Overview

Understanding and leveraging consumer behavior presents significant business opportunities. Traditional deep learning methods, despite their predictive strengths, lack interpretability and explicit modeling of consumer decision-making processes. Economic theories suggest that consumers typically follow a sequential search strategy, evaluating alternatives sequentially to find the best match for their preferences.

To address this challenge, we developed the **Sequential Search Transformer (SST)**, which integrates deep learning approaches with economic sequential search theory to accurately model consumer search and purchase decisions.

## Key Contributions

- SST combines the predictive power of deep learning with economic theory, resulting in improved interpretability and decision modeling.
- SST explicitly models consumer search and decision-making across sessions and sequentially resolves uncertainty in product utility.
- Demonstrated through Monte Carlo simulations, SST effectively recovers parameters from simulated datasets.
- Empirical evaluations indicate SST's superior performance compared to state-of-the-art deep learning and structural econometric models.

## Monte Carlo Simulations

The simulations provided in this repository serve the following purposes:

- **Parameter Recovery:** Verify SST's capability to recover known parameters from simulated datasets.
- **Model Validation:** Assess the robustness and reliability of SST under controlled conditions.

## Repository Structure



## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

